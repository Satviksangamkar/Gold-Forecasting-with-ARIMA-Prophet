{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad711d57",
   "metadata": {},
   "source": [
    "# XAUUSD Time Series Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook performs a comprehensive time series analysis on XAUUSD historical data. It covers data preprocessing, exploratory data analysis, time series modeling with ARIMA and Prophet, and a comparison of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a9201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import joblib\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file with the correct delimiter (comma in this case)\n",
    "data = pd.read_csv('XAUUSD_historical_data.csv', sep=',')\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "# Sort data by date in ascending order\n",
    "data = data.sort_values('Date')\n",
    "\n",
    "# Set 'Date' as the index\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "# Display data info\n",
    "data.info()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8eddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the closing price over time to visualize the historical price movements\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['Close'], label='Close Price')\n",
    "plt.title('XAUUSD Close Price Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decompose the time series to analyze the trend, seasonality, and residuals\n",
    "decomposition = seasonal_decompose(data['Close'], model='multiplicative', period=30)\n",
    "decomposition.plot()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform Augmented Dickey-Fuller test to check if the time series is stationary\n",
    "adf_test = adfuller(data['Close'])\n",
    "print(f'ADF Statistic: {adf_test[0]}')\n",
    "print(f'p-value: {adf_test[1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit ARIMA model to the time series data\n",
    "model = ARIMA(data['Close'], order=(5, 1, 0))  # Example order; tune as needed\n",
    "arima_result = model.fit()\n",
    "\n",
    "# Forecast future values using the fitted ARIMA model\n",
    "forecast = arima_result.forecast(steps=10)\n",
    "print(forecast)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8285e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forecast future values and visualize them alongside historical data\n",
    "future_forecast = arima_result.forecast(steps=30)\n",
    "print(future_forecast)\n",
    "\n",
    "# Plot the historical data and the forecasted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['Close'], label='Historical Data')\n",
    "plt.plot(pd.date_range(start=data.index[-1], periods=31, freq='D')[1:], future_forecast, label='Forecast')\n",
    "plt.title('XAUUSD Close Price Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b183ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Calculate performance metrics for the ARIMA model\n",
    "mae = mean_absolute_error(data['Close'], arima_result.fittedvalues)\n",
    "mse = mean_squared_error(data['Close'], arima_result.fittedvalues)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378a0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# Save the ARIMA model to a file\n",
    "joblib.dump(arima_result, 'arima_model.pkl')\n",
    "\n",
    "# To load the model later\n",
    "# model = joblib.load('arima_model.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ffa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Automatically find the best ARIMA parameters using auto_arima\n",
    "auto_model = auto_arima(data['Close'], seasonal=False, trace=True)\n",
    "print(auto_model.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c44e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze residuals of the ARIMA model\n",
    "residuals = arima_result.resid\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(residuals)\n",
    "plt.title('ARIMA Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Perform Ljung-Box test to check if residuals are independent\n",
    "lb_test = acorr_ljungbox(residuals, lags=[10], return_df=True)\n",
    "print(lb_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff963a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for the Prophet model\n",
    "data_reset = data.reset_index()\n",
    "data_reset = data_reset.rename(columns={'index': 'Date'})  # Rename index column to 'Date'\n",
    "data_reset['Date'] = pd.to_datetime(data_reset['Date'])\n",
    "prophet_data = data_reset[['Date', 'Close']].rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "\n",
    "# Initialize and fit the Prophet model\n",
    "model = Prophet()\n",
    "model.fit(prophet_data)\n",
    "\n",
    "# Create a future dataframe and make predictions\n",
    "future = model.make_future_dataframe(periods=30)  # Predict for 30 days into the future\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Plot the forecast\n",
    "fig = model.plot(forecast)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust the Prophet model with different hyperparameters\n",
    "model = Prophet(changepoint_prior_scale=0.1, seasonality_prior_scale=10.0)\n",
    "model.fit(prophet_data)\n",
    "\n",
    "# Check the length of the dataset\n",
    "print(f\"Number of data points: {len(prophet_data)}\")\n",
    "\n",
    "# Perform cross-validation on the Prophet model\n",
    "from prophet.diagnostics import cross_validation\n",
    "\n",
    "try:\n",
    "    # Adjust horizon and period to match the dataset size\n",
    "    cv_results = cross_validation(model, horizon='7 days', period='1 day')\n",
    "    print(cv_results.head())\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501469d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_lagged_features(data, lags):\n",
    "    # Create lagged features for time series forecasting\n",
    "    df = data.copy()\n",
    "    for i in range(1, lags + 1):\n",
    "        df[f'lag_{i}'] = df['Close'].shift(i)\n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values\n",
    "    return df\n",
    "\n",
    "# Create lagged features with a lag of 5 periods\n",
    "lagged_data = create_lagged_features(data, lags=5)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Extract features and target variable\n",
    "features = lagged_data.drop('Close', axis=1)\n",
    "target = lagged_data['Close']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def prepare_lstm_data(features, target, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - time_steps):\n",
    "        X.append(features[i:i + time_steps])\n",
    "        y.append(target[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set time steps for LSTM\n",
    "time_steps = 5\n",
    "X, y = prepare_lstm_data(features_scaled, target, time_steps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_moving_averages(data, windows):\n",
    "    # Add moving averages to the dataset\n",
    "    df = data.copy()\n",
    "    for window in windows:\n",
    "        df[f'ma_{window}'] = df['Close'].rolling(window=window).mean()\n",
    "    df.dropna(inplace=True)  # Drop rows with NaN values\n",
    "    return df\n",
    "\n",
    "# Add moving averages with different window sizes\n",
    "moving_avg_windows = [5, 10, 20]\n",
    "ma_data = add_moving_averages(data, moving_avg_windows)\n",
    "\n",
    "# Extract features and target variable\n",
    "features = ma_data.drop('Close', axis=1)\n",
    "target = ma_data['Close']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Prepare data for LSTM\n",
    "X, y = prepare_lstm_data(features_scaled, target, time_steps)\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
